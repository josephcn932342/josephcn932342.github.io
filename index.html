<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.37.1" />
  <meta name="author" content="Joseph Lin">
  <meta name="description" content="Title Here">

  
  <link rel="alternate" hreflang="en-us" href="https://josephcn932342.github.io/">

          
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  
  <link rel="stylesheet" href="/css/academic1.css">
  

  

  
  <link rel="alternate" href="https://josephcn932342.github.io/index.xml" type="application/rss+xml" title="Joseph Lin">
  <link rel="feed" href="https://josephcn932342.github.io/index.xml" type="application/rss+xml" title="Joseph Lin">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://josephcn932342.github.io/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Joseph Lin">
  <meta property="og:url" content="https://josephcn932342.github.io/">
  <meta property="og:title" content="Joseph Lin">
  <meta property="og:description" content="Title Here">
  <meta property="og:locale" content="en-us">
  
  <meta property="og:updated_time" content="2016-04-20T00:00:00&#43;00:00">
  

  

  <title>Joseph Lin</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Joseph Lin</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        

        
          
        

        <li class="nav-item">
          <a href="/#about" data-target="#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#publications_selected" data-target="#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#experience" data-target="#experience">
            
            <span>Experience</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#contact" data-target="#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>



<span id="homepage" style="display: none"></span>


  





  
  
  
  <section id="about" class="home-section">
    <div class="container">
      



<div class="row" itemprop="author" itemscope itemtype="http://schema.org/Person" itemref="person-email person-address">
  <div class="col-xs-12 col-md-4">
    <div id="profile">

      
      <div class="portrait" style="background-image: url('https://josephcn932342.github.io/img/joseph.png');"></div>
      <meta itemprop="image" content="https://josephcn932342.github.io/img/joseph.png">
      

      <div class="portrait-title">
        <h2 itemprop="name">Joseph Lin</h2>
        <h3 itemprop="jobTitle">林碩彥</h3>

        
        

        
        <h3 itemprop="worksFor" itemscope itemtype="http://schema.org/Organization">
          
          <span itemprop="name"></span>
          
        </h3>
        
      </div>

      <link itemprop="url" href="https://josephcn932342.github.io/">

      <ul class="network-icon" aria-hidden="true">
        
        
        <li>
          <a itemprop="sameAs" href="mailto:josephcn932342@gmail.com" target="_blank" rel="noopener">
            <i class="fa fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        <li>
          <a itemprop="sameAs" href="https://scholar.google.com/citations?user=F8rGi7wAAAAJ&hl=zh-TW&oi=sra" target="_blank" rel="noopener">
            <i class="ai ai-google-scholar big-icon"></i>
          </a>
        </li>
           
        
        <li>
          <a itemprop="sameAs" href="https://github.com/josephcn932342" target="_blank" rel="noopener">
            <i class="fa fa-github big-icon"></i>
          </a>
        </li>
        
        
      </ul>

    </div>
  </div>
  <div class="col-xs-12 col-md-8" itemprop="description">

    

<h1 id="about">About</h1>

<p><br/>
During my Master's studies in Computer Science and Information Engineering at <a href="https://www.csie.ncu.edu.tw" target="_blank">National Central University</a>, I served as a research assistant at both the <a href="https://www.iis.sinica.edu.tw/zh/index.html" target="_blank">Institute of Information Science</a>  and the <a href="https://www.citi.sinica.edu.tw" target="_blank">Research Center for Information Technology Innovation</a> at Academia Sinica with Professors Chia-Ching Wang and Jun-Cheng Chen. My expertise lies in Computer Vision, Generative Models, Object Detection, and Adversarial Machine Learning. My recent research projects involved leveraging Diffusion Models for adversarial attacks and generating realistic, style-transferred videos.<br/>
<br/>
<br style="line-height: 1px" />
<img src="/img/logo.png"  /></p>


    <div class="row">

      

      

    </div>
  </div>
</div>

    </div>
  </section>
  

  
  
  
  <section id="publications_selected" class="home-section">
    <div class="container">
      



<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">
    <h1>Selected Publications</h1>
    
  </div>
  <div class="col-xs-12 col-md-8">
    

    
      
    

    
    
      
        <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
        <img src="/img/medm.jpg" class="pub-banner"
             itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://scholar.google.com/citations?view_op=view_citation&hl=zh-TW&user=F8rGi7wAAAAJ&citation_for_view=F8rGi7wAAAAJ:2osOgNQ5qMEC" itemprop="url">MeDM: Mediating Image Diffusion Models for Video-to-Video Translation with Temporal Correspondence Guidance</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        This study introduces an efficient and effective method, MeDM, that utilizes pre-trained image Diffusion Models for video-to-video translation with consistent temporal flow. The proposed framework can render videos from scene position information, such as a normal G-buffer, or perform text-guided editing on videos captured in real-world scenarios. We employ explicit optical flows to construct a practical coding that enforces physical constraints on generated frames and mediates independent frame-wise scores. By leveraging this coding, maintaining temporal consistency in the generated videos can be framed as an optimization problem with a closed-form solution. To ensure compatibility with Stable Diffusion, we also suggest a workaround for modifying observed-space scores in latent-space Diffusion Models. Notably, MeDM does not require fine-tuning or test-time optimization of the Diffusion Models. Through extensive qualitative, quantitative, and subjective experiments on various benchmarks, the study demonstrates the effectiveness and superiority of the proposed approach.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Ernie Chu, Tzuhsuan Huang, Shuo-Yen Lin, Jun-Cheng Chen
        
      </div>

      <div class="pub-publication">
        AAAI (Poster),&nbsp;2024.
      </div>

      <div class="pub-links">
    <a class="btn btn-primary btn-outline btn-xs" href="https://medm2023.github.io" target="_blank" rel="noopener">
  Project Page 
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://medm2023.github.io/medm-poster.pdf" target="_blank" rel="noopener">
  Poster
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/aiiu-lab/MeDM" target="_blank" rel="noopener">
  Github
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/2308.10079" target="_blank" rel="noopener">
  ArXiv
</a>


      </div>

    </div>
  </div>
</div>
      
    
      
        <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
        <img src="/img/diff2conf.png" class="pub-banner"
             itemprop="image">
      </a>
    </div>
    <div class="col-md-12"> 


    

      <h3 class="article-title" itemprop="name">
        <a href="https://scholar.google.com/citations?view_op=view_citation&hl=zh-TW&user=F8rGi7wAAAAJ&citation_for_view=F8rGi7wAAAAJ:d1gkVwhDpl0C" itemprop="url">Diffusion to Confusion: Naturalistic Adversarial Patch Generation Based on Diffusion Model for Object Detector</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        Many physical adversarial patch generation methods are widely proposed to protect personal privacy from malicious monitoring using object detectors. However, they usually fail to generate satisfactory patch images in terms of both stealthiness and attack performance without making huge efforts on careful hyperparameter tuning. To address this issue, we propose a novel naturalistic adversarial patch generation method based on the diffusion models (DM). Through sampling the optimal image from the DM model pretrained upon natural images, it allows us to stably craft high-quality and naturalistic physical adversarial patches to humans without suffering from serious mode collapse problems as other deep generative models. To the best of our knowledge, we are the first to propose DM-based naturalistic adversarial patch generation for object detectors. With extensive quantitative, qualitative, and subjective experiments, the results demonstrate the effectiveness of the proposed approach to generate better-quality and more naturalistic adversarial patches while achieving acceptable attack performance than other state-of-the-art patch generation methods. We also show various generation trade-offs under different conditions.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Shuo-Yen Lin, Ernie Chu, Che-Hsien Lin, Jun-Cheng Chen, Jia-Ching Wang
        
      </div>

      <div class="pub-publication">
        Under Review, 2023.
      </div>

      <div class="pub-links">
        


<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/2307.08076" target="_blank" rel="noopener">
  ArXiv
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://hdl.handle.net/11296/gswad7" target="_blank" rel="noopener">
  Master Thesis
</a>




      </div>

    </div>
  </div>
</div>

      
    
      
        <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
        <img src="/img/CMUA_UTUA.png" class="pub-banner"
             itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://ieeexplore.ieee.org/abstract/document/10008794" itemprop="url">A Comparative Study of Cross-Model Universal Adversarial Perturbation for Face Forgery</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        Although the rapid development of deep generative models (DGM) enables diverse applications of content creation, increasing illegal uses of the technologies also severely threaten the privacy and security of personal information, especially for faces. Several previous works have been proposed to leverage adversarial attacks to fight against these malicious manipulations by adding an imperceptible perturbation to each input image to disrupt the output. In addition, to improve its scalability, a sequential cross-model universal perturbation attack has been proposed to learn a common adversarial perturbation to defend the images from the manipulation of multiple DGMs. However, we find that the order of DGMs for the adversarial perturbation generation does matter and influence the final defense performance. To address this issue, we propose to generate the universal perturbation through joint optimization of multiple DGMs. From the extensive experimental results, we find that the universal perturbation generated by the proposed method can successfully disrupt the output faces of multiple DGMs at the same time and achieves higher attack success rates than the previous state-of-the-art method based on the sequential generation, even under the situations where the model robustness of DGMs are enhanced by random perturbations.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Shuo-Yen Lin, Jun-Cheng Chen, Jia-Ching Wang
        
      </div>

      <div class="pub-publication">
        VCIP(Oral),&nbsp;2022.
      </div>

      <div class="pub-links">
        


<a class="btn btn-primary btn-outline btn-xs" href="https://ieeexplore.ieee.org/abstract/document/10008794" target="_blank" rel="noopener">
  IEEE
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://research.sinica.edu.tw/deepfake-detection-generative-ai-jun-cheng-chen/" target="_blank" rel="noopener">
  Report
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://www.youtube.com/watch?v=0w8YEz5JLgc" target="_blank" rel="noopener">
  Presentation
</a>



      </div>

    </div>
  </div>
</div>
 
      
    
      
        <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
        <img src="/img/prcv.png" class="pub-banner"
             itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://link.springer.com/chapter/10.1007/978-3-030-60639-8_38" itemprop="url">Deep Face Recognition Based on Penalty Cosface</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        Face recognition has achieved great progress because of the advancement of deep convolutional neural networks (CNNs) techniques. The Softmax loss is one of the most popular loss function for deep learning models. In many situations, face images are captured in the unconstrained environments with changing poses and illuminations, making face recognition very challenging because of the dramatic appearance variations. The models trained with the Softmax loss may fail to extract discriminative information for the face images with extreme illumination or pose conditions. Recently, Cosface has been proven effective for improving the generalization ability of the Softmax loss. Derived from Cosface, we propose a novel method named Penalty Cosface to address the unconstrained face recognition challenges and learn discriminative features. Specifically, we design a variant of Cosface that remove radial variations by penalizing \ell _2-normalized constraints of the features and weights. Therefore, the discriminative ability of the Penalty Cosface is guaranteed by the large margin of the Cosface, and the penalty term is beneficial to simplifying the gradient calculations. Experimental results show that the Penalty Cosface improves the discriminative power of deep networks and outperforms the other variants of Softmax loss.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Shuo-Yan Lin, Jian-Xiong Tang, Zhan-Xiang Feng, Jian-Huang Lai
        
      </div>

      <div class="pub-publication">
        PRCV(Oral),&nbsp;2020.
      </div>

      <div class="pub-links">
        


<a class="btn btn-primary btn-outline btn-xs" href="https://link.springer.com/chapter/10.1007/978-3-030-60639-8_38" target="_blank" rel="noopener">
  Springer
</a>



      </div>

    </div>
  </div>
</div>


  </div>
</div>

    </div>
  </section>
  

  
  
  
  <section id="experience" class="home-section">
    <div class="container">
      


<div class="row">
  
  <div class="col-xs-12 col-md-4 section-heading">
    <h1>Experience</h1>
    
  </div>
  <div class="col-xs-12 col-md-8">
    <ul>
<li>Research Assistant: <strong>
中央研究院資訊科學研究所 Institute of Information Science, Academia Sinica</strong>  Sep 2022 - Jun 2023 <br />
<br /></li>
<li>Research Assistant: <strong>中央研究院資訊科技創新研究中心 Research Center for Information Technology Innovation, Academia Sinica</strong> Oct 2021 - Aug 2022, Jul 2023 - Aug 2023 <br /><br /></li>
</ul>

  </div>
  
</div>

    </div>
  </section>
  

  
  
  

  

  
  
  

  
  
  <section id="contact" class="home-section">
    <div class="container">
      




<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">
    <h1>Contact</h1>
    
  </div>
  <div class="col-xs-12 col-md-8">
    

    <ul class="fa-ul" itemscope>

      
      <li>
        <i class="fa-li fa fa-envelope fa-2x" aria-hidden="true"></i>
        <span id="person-email" itemprop="email"><a href="mailto:josephcn932342@gmail.com">josephcn932342@gmail.com</a></span>
      </li>
      

      


      

      

    </ul>

    

  </div>
</div>

    </div>
  </section>
  



<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2024 Joseph Lin &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    

  </body>
</html>


